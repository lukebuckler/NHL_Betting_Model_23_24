{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#use the mapping dictionary imported from the teams.csv file to change all of the full team names to the abbreviation\n",
    "\n",
    "abbreviations_df = pd.read_csv('teams.csv')\n",
    "mapping_dict = dict(zip(abbreviations_df['Team'], abbreviations_df['Abbrv']))\n",
    "\n",
    "# mapping function\n",
    "def update_and_overwrite_file(file_path, mapping_dict):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Team'] = df['Team'].map(mapping_dict)\n",
    "    df.to_csv(file_path, index=False)  # Overwrite the original file\n",
    "\n",
    "file_paths = ['C:/Users/luken/Desktop/NHL_Model/Raw_data/20_21_games.csv', 'C:/Users/luken/Desktop/NHL_Model/Raw_data/21_22_games.csv', 'C:/Users/luken/Desktop/NHL_Model/Raw_data/22_23_games.csv']\n",
    "\n",
    "#loop through the files and apply the function\n",
    "for file_path in file_paths:\n",
    "    update_and_overwrite_file(file_path, mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#use the mappping dictionary to change all the shortenned team names to the abbreviation\n",
    "abbreviations_df = pd.read_csv('teams.csv')\n",
    "mapping_dict = dict(zip(abbreviations_df['Name'], abbreviations_df['Abbrv']))\n",
    "\n",
    "#the team names are within the string in the \"game\" column in the file so to change them we need to deconstruct the string into the parts, rename the teams with the mapping dictionary and then reconstruct the string\n",
    "def replace_team_names(game_string, mapping_dict):\n",
    "    pattern = r' (\\d{4}-\\d{2}-\\d{2}) - ([\\w\\s]+) (\\d+), ([\\w\\s]+) (\\d+)'\n",
    "    match = re.match(pattern, game_string)\n",
    "\n",
    "    if match:\n",
    "        date, team1, score1, team2, score2 = match.groups()\n",
    "        team1_abbr = mapping_dict.get(team1.strip(), team1)  # Fallback to original if not found\n",
    "        team2_abbr = mapping_dict.get(team2.strip(), team2)  # Fallback to original if not found\n",
    "\n",
    "        return f\"{date} - {team1_abbr} {score1}, {team2_abbr} {score2}\"\n",
    "    else:\n",
    "        return game_string \n",
    "\n",
    "def update_and_overwrite_file(file_path, mapping_dict):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Game'] = df['Game'].apply(lambda x: replace_team_names(x, mapping_dict))\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "file_paths = ['C:/Users/luken/Desktop/NHL_Model/Raw_data/20_21_games.csv', 'C:/Users/luken/Desktop/NHL_Model/Raw_data/21_22_games.csv', 'C:/Users/luken/Desktop/NHL_Model/Raw_data/22_23_games.csv']\n",
    "\n",
    "#loop through again\n",
    "for file_path in file_paths:\n",
    "    update_and_overwrite_file(file_path, mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved 20_21_games.csv to C:/Users/luken/Desktop/NHL_Model/Selected_data\n",
      "Processed and saved 21_22_games.csv to C:/Users/luken/Desktop/NHL_Model/Selected_data\n",
      "Processed and saved 22_23_games.csv to C:/Users/luken/Desktop/NHL_Model/Selected_data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "input_dir = \"C:/Users/luken/Desktop/NHL_Model/Raw_data/\" \n",
    "output_dir = \"C:/Users/luken/Desktop/NHL_Model/Selected_data\"  \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#drop the unwanted columns from the files\n",
    "#every stat has a for column, agaisnt column, and a for% column, so we willl drop all of the columns that have a % in the name and jsut use the for and agaisnt counts to reduce redundancy in the data\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f)) and f.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    input_file_path = os.path.join(input_dir, file)\n",
    "    output_file_path = os.path.join(output_dir, file)\n",
    "    \n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    cols_to_drop = [col for col in df.columns if '%' in col]\n",
    "    \n",
    "    #dropping other unnecceasry columns (no way to get attendance before the games so we cant use it to predict future games)\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    df.drop('Unnamed: 2', axis=1, inplace=True)\n",
    "    df.drop('Attendance', axis=1, inplace=True)\n",
    "    df.drop('TOI', axis=1, inplace=True)\n",
    "\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files organized by year and saved in C:/Users/luken/Desktop/NHL_Model/Sorted_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "input_directory = \"C:/Users/luken/Desktop/NHL_Model/Selected_data/\"\n",
    "base_output_directory = \"C:/Users/luken/Desktop/NHL_Model/Sorted_data\"\n",
    "\n",
    "#each file represents all of the games from the past year, with every unique game occuring twice, once for the home team and then a second time from the perspective fo the away team\n",
    "#the value in the \"team\" column shows which team's persepctive the stats are from, so we can sort each csv file into a unique file for each team from each year\n",
    "\n",
    "#iterate through the files and create new files for each team's games for each year\n",
    "for file_name in os.listdir(input_directory):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        year = file_name.split('_games.csv')[0]\n",
    "\n",
    "        year_directory = os.path.join(base_output_directory, year)\n",
    "        if not os.path.exists(year_directory):\n",
    "            os.makedirs(year_directory)\n",
    "\n",
    "        file_path = os.path.join(input_directory, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        #using this patern from the stirng in the \"game\" column we can get the home and away teams and scores, and then use the scores to determine the winner of the game\n",
    "        pattern = r'(\\d{4}-\\d{2}-\\d{2}) - ([\\w\\s]+) (\\d+), ([\\w\\s]+) (\\d+)'\n",
    "        df[['Date', 'AwayTeam', 'AwayScore', 'HomeTeam', 'HomeScore']] = df['Game'].str.extract(pattern)\n",
    "        df['HomeResult'] = 'Draw'\n",
    "        df.loc[df['HomeScore'] > df['AwayScore'], 'HomeResult'] = 'Won'\n",
    "        df.loc[df['HomeScore'] < df['AwayScore'], 'HomeResult'] = 'Lost'\n",
    "        \n",
    "\n",
    "\n",
    "        team_subsets = {team: df[df['Team'] == team] for team in df['Team'].unique()}\n",
    "\n",
    "        for team, subset in team_subsets.items():\n",
    "            team_file_name = f\"{team}.csv\"\n",
    "            team_file_path = os.path.join(year_directory, team_file_name)\n",
    "            subset.to_csv(team_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ANA.csv inside 20_21\n",
      "Processed ARI.csv inside 20_21\n",
      "Processed BOS.csv inside 20_21\n",
      "Processed BUF.csv inside 20_21\n",
      "Processed CAR.csv inside 20_21\n",
      "Processed CBJ.csv inside 20_21\n",
      "Processed CGY.csv inside 20_21\n",
      "Processed CHI.csv inside 20_21\n",
      "Processed COL.csv inside 20_21\n",
      "Processed DAL.csv inside 20_21\n",
      "Processed DET.csv inside 20_21\n",
      "Processed EDM.csv inside 20_21\n",
      "Processed FLA.csv inside 20_21\n",
      "Processed LA.csv inside 20_21\n",
      "Processed MIN.csv inside 20_21\n",
      "Processed MTL.csv inside 20_21\n",
      "Processed NJ.csv inside 20_21\n",
      "Processed NSH.csv inside 20_21\n",
      "Processed NYI.csv inside 20_21\n",
      "Processed NYR.csv inside 20_21\n",
      "Processed OTT.csv inside 20_21\n",
      "Processed PHI.csv inside 20_21\n",
      "Processed PIT.csv inside 20_21\n",
      "Processed SJ.csv inside 20_21\n",
      "Processed STL.csv inside 20_21\n",
      "Processed TB.csv inside 20_21\n",
      "Processed TOR.csv inside 20_21\n",
      "Processed VAN.csv inside 20_21\n",
      "Processed VGK.csv inside 20_21\n",
      "Processed WPG.csv inside 20_21\n",
      "Processed WSH.csv inside 20_21\n",
      "Processed ANA.csv inside 21_22\n",
      "Processed ARI.csv inside 21_22\n",
      "Processed BOS.csv inside 21_22\n",
      "Processed BUF.csv inside 21_22\n",
      "Processed CAR.csv inside 21_22\n",
      "Processed CBJ.csv inside 21_22\n",
      "Processed CGY.csv inside 21_22\n",
      "Processed CHI.csv inside 21_22\n",
      "Processed COL.csv inside 21_22\n",
      "Processed DAL.csv inside 21_22\n",
      "Processed DET.csv inside 21_22\n",
      "Processed EDM.csv inside 21_22\n",
      "Processed FLA.csv inside 21_22\n",
      "Processed LA.csv inside 21_22\n",
      "Processed MIN.csv inside 21_22\n",
      "Processed MTL.csv inside 21_22\n",
      "Processed NJ.csv inside 21_22\n",
      "Processed NSH.csv inside 21_22\n",
      "Processed NYI.csv inside 21_22\n",
      "Processed NYR.csv inside 21_22\n",
      "Processed OTT.csv inside 21_22\n",
      "Processed PHI.csv inside 21_22\n",
      "Processed PIT.csv inside 21_22\n",
      "Processed SEA.csv inside 21_22\n",
      "Processed SJ.csv inside 21_22\n",
      "Processed STL.csv inside 21_22\n",
      "Processed TB.csv inside 21_22\n",
      "Processed TOR.csv inside 21_22\n",
      "Processed VAN.csv inside 21_22\n",
      "Processed VGK.csv inside 21_22\n",
      "Processed WPG.csv inside 21_22\n",
      "Processed WSH.csv inside 21_22\n",
      "Processed ANA.csv inside 22_23\n",
      "Processed ARI.csv inside 22_23\n",
      "Processed BOS.csv inside 22_23\n",
      "Processed BUF.csv inside 22_23\n",
      "Processed CAR.csv inside 22_23\n",
      "Processed CBJ.csv inside 22_23\n",
      "Processed CGY.csv inside 22_23\n",
      "Processed CHI.csv inside 22_23\n",
      "Processed COL.csv inside 22_23\n",
      "Processed DAL.csv inside 22_23\n",
      "Processed DET.csv inside 22_23\n",
      "Processed EDM.csv inside 22_23\n",
      "Processed FLA.csv inside 22_23\n",
      "Processed LA.csv inside 22_23\n",
      "Processed MIN.csv inside 22_23\n",
      "Processed MTL.csv inside 22_23\n",
      "Processed NJ.csv inside 22_23\n",
      "Processed NSH.csv inside 22_23\n",
      "Processed NYI.csv inside 22_23\n",
      "Processed NYR.csv inside 22_23\n",
      "Processed OTT.csv inside 22_23\n",
      "Processed PHI.csv inside 22_23\n",
      "Processed PIT.csv inside 22_23\n",
      "Processed SEA.csv inside 22_23\n",
      "Processed SJ.csv inside 22_23\n",
      "Processed STL.csv inside 22_23\n",
      "Processed TB.csv inside 22_23\n",
      "Processed TOR.csv inside 22_23\n",
      "Processed VAN.csv inside 22_23\n",
      "Processed VGK.csv inside 22_23\n",
      "Processed WPG.csv inside 22_23\n",
      "Processed WSH.csv inside 22_23\n"
     ]
    }
   ],
   "source": [
    "#loop through the files for each team in each year to calculate the number of days of rest each team had going into that game by taking the difference between the number of days between each game (time diff) minus 1 (days of rest)\n",
    "\n",
    "root_dir = 'sorted_data/'\n",
    "\n",
    "subfolders = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    dir_path = os.path.join(root_dir, subfolder)\n",
    "    \n",
    "   \n",
    "    all_files = [f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f)) and f.endswith('.csv')]\n",
    "\n",
    "    for file in all_files:\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'Date' in df.columns:\n",
    "            date_col = 'Date'\n",
    "        else:\n",
    "            print(f\"Cannot find date column in file {file} inside {subfolder}. Skipping...\")\n",
    "            continue\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "        df['time_diff'] = df[date_col].diff()\n",
    "        df['days_of_rest'] = df['time_diff'].dt.days - 1\n",
    "        df.drop('time_diff', axis=1, inplace=True)\n",
    "        df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#create a function to calculate the rolling average of the 10 games prior to each game to get the rolling average of stats going into each game\n",
    "def calculate_rolling_average(df, columns, window=10):\n",
    "    rolling_df = df[columns].rolling(window=window, min_periods=10).mean().shift(1)\n",
    "    return rolling_df\n",
    "\n",
    "base_path = 'sorted_data/'\n",
    "#create a new folder to put the new processed data into\n",
    "average_data_path = 'average_data/'\n",
    "os.makedirs(average_data_path, exist_ok=True)\n",
    "\n",
    "for year_folder in os.listdir(base_path):\n",
    "    year_path = os.path.join(base_path, year_folder)\n",
    "\n",
    "    if os.path.isdir(year_path):\n",
    "        year_avg_folder_path = os.path.join(average_data_path, f'avg_{year_folder}')\n",
    "        os.makedirs(year_avg_folder_path, exist_ok=True)\n",
    "\n",
    "        for team_file in os.listdir(year_path):\n",
    "            if team_file.endswith('.csv'):\n",
    "                team_path = os.path.join(year_path, team_file)\n",
    "                df = pd.read_csv(team_path)\n",
    "                #select the columns we dont want to average (all non numerical, score and days of rest)\n",
    "                selected_columns = ['Game', 'Team', 'Date', 'AwayTeam', 'AwayScore', 'HomeTeam', 'HomeScore', 'HomeResult', 'days_of_rest']\n",
    "                other_columns = df.columns.difference(selected_columns)\n",
    "                rolling_df = calculate_rolling_average(df, other_columns)\n",
    "                #re-combine the non-averaged columns with the averaged columns\n",
    "                combined_df = pd.concat([df[selected_columns], rolling_df], axis=1)\n",
    "\n",
    "                processed_file_path = os.path.join(year_avg_folder_path, f'{team_file}')\n",
    "                combined_df.to_csv(processed_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Date</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>AwayScore</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>HomeScore</th>\n",
       "      <th>HomeResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-13 - PIT 3, PHI 6</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>PIT</td>\n",
       "      <td>3</td>\n",
       "      <td>PHI</td>\n",
       "      <td>6</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-13 - CHI 1, TB 5</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>TB</td>\n",
       "      <td>5</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-13 - MTL 4, TOR 5</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>MTL</td>\n",
       "      <td>4</td>\n",
       "      <td>TOR</td>\n",
       "      <td>5</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-13 - VAN 5, EDM 3</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>VAN</td>\n",
       "      <td>5</td>\n",
       "      <td>EDM</td>\n",
       "      <td>3</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-13 - STL 4, COL 1</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>STL</td>\n",
       "      <td>4</td>\n",
       "      <td>COL</td>\n",
       "      <td>1</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-01-14 - WSH 6, BUF 4</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>WSH</td>\n",
       "      <td>6</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-01-14 - BOS 3, NJ 2</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>BOS</td>\n",
       "      <td>3</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-01-14 - NYI 4, NYR 0</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>NYI</td>\n",
       "      <td>4</td>\n",
       "      <td>NYR</td>\n",
       "      <td>0</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-01-14 - CAR 3, DET 0</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>CAR</td>\n",
       "      <td>3</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-01-14 - CBJ 1, NSH 3</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>CBJ</td>\n",
       "      <td>1</td>\n",
       "      <td>NSH</td>\n",
       "      <td>3</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-01-14 - CGY 3, WPG 4</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>CGY</td>\n",
       "      <td>3</td>\n",
       "      <td>WPG</td>\n",
       "      <td>4</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-01-14 - VAN 2, EDM 5</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>VAN</td>\n",
       "      <td>2</td>\n",
       "      <td>EDM</td>\n",
       "      <td>5</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-01-14 - SJ 4, ARI 3</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>SJ</td>\n",
       "      <td>4</td>\n",
       "      <td>ARI</td>\n",
       "      <td>3</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-01-14 - ANA 2, VGK 5</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>ANA</td>\n",
       "      <td>2</td>\n",
       "      <td>VGK</td>\n",
       "      <td>5</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-01-14 - MIN 4, LA 3</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>MIN</td>\n",
       "      <td>4</td>\n",
       "      <td>LA</td>\n",
       "      <td>3</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-01-15 - WSH 2, BUF 1</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>WSH</td>\n",
       "      <td>2</td>\n",
       "      <td>BUF</td>\n",
       "      <td>1</td>\n",
       "      <td>Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-01-15 - PIT 2, PHI 5</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>PIT</td>\n",
       "      <td>2</td>\n",
       "      <td>PHI</td>\n",
       "      <td>5</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021-01-15 - CHI 2, TB 5</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>CHI</td>\n",
       "      <td>2</td>\n",
       "      <td>TB</td>\n",
       "      <td>5</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2021-01-15 - TOR 3, OTT 5</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>TOR</td>\n",
       "      <td>3</td>\n",
       "      <td>OTT</td>\n",
       "      <td>5</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021-01-15 - STL 0, COL 8</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>STL</td>\n",
       "      <td>0</td>\n",
       "      <td>COL</td>\n",
       "      <td>8</td>\n",
       "      <td>Won</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Game        Date AwayTeam AwayScore HomeTeam  \\\n",
       "1   2021-01-13 - PIT 3, PHI 6  2021-01-13      PIT         3      PHI   \n",
       "3    2021-01-13 - CHI 1, TB 5  2021-01-13      CHI         1       TB   \n",
       "5   2021-01-13 - MTL 4, TOR 5  2021-01-13      MTL         4      TOR   \n",
       "7   2021-01-13 - VAN 5, EDM 3  2021-01-13      VAN         5      EDM   \n",
       "9   2021-01-13 - STL 4, COL 1  2021-01-13      STL         4      COL   \n",
       "11  2021-01-14 - WSH 6, BUF 4  2021-01-14      WSH         6      BUF   \n",
       "13   2021-01-14 - BOS 3, NJ 2  2021-01-14      BOS         3       NJ   \n",
       "15  2021-01-14 - NYI 4, NYR 0  2021-01-14      NYI         4      NYR   \n",
       "17  2021-01-14 - CAR 3, DET 0  2021-01-14      CAR         3      DET   \n",
       "19  2021-01-14 - CBJ 1, NSH 3  2021-01-14      CBJ         1      NSH   \n",
       "21  2021-01-14 - CGY 3, WPG 4  2021-01-14      CGY         3      WPG   \n",
       "23  2021-01-14 - VAN 2, EDM 5  2021-01-14      VAN         2      EDM   \n",
       "25   2021-01-14 - SJ 4, ARI 3  2021-01-14       SJ         4      ARI   \n",
       "27  2021-01-14 - ANA 2, VGK 5  2021-01-14      ANA         2      VGK   \n",
       "29   2021-01-14 - MIN 4, LA 3  2021-01-14      MIN         4       LA   \n",
       "31  2021-01-15 - WSH 2, BUF 1  2021-01-15      WSH         2      BUF   \n",
       "33  2021-01-15 - PIT 2, PHI 5  2021-01-15      PIT         2      PHI   \n",
       "35   2021-01-15 - CHI 2, TB 5  2021-01-15      CHI         2       TB   \n",
       "37  2021-01-15 - TOR 3, OTT 5  2021-01-15      TOR         3      OTT   \n",
       "39  2021-01-15 - STL 0, COL 8  2021-01-15      STL         0      COL   \n",
       "\n",
       "   HomeScore HomeResult  \n",
       "1          6        Won  \n",
       "3          5        Won  \n",
       "5          5        Won  \n",
       "7          3       Lost  \n",
       "9          1       Lost  \n",
       "11         4       Lost  \n",
       "13         2       Lost  \n",
       "15         0       Lost  \n",
       "17         0       Lost  \n",
       "19         3        Won  \n",
       "21         4        Won  \n",
       "23         5        Won  \n",
       "25         3       Lost  \n",
       "27         5        Won  \n",
       "29         3       Lost  \n",
       "31         1       Lost  \n",
       "33         5        Won  \n",
       "35         5        Won  \n",
       "37         5        Won  \n",
       "39         8        Won  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in order to build the data set for creating the training set, we need to take a list of each game from the original files\n",
    "directory_path = 'Raw_data'\n",
    "\n",
    "# create the initial empty dataframe to add the games to \n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "#loop through all of the files in the raw data folder and add the game into the the master dataframe\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'Game' in df.columns:\n",
    "            master_df = pd.concat([master_df, df[['Game']]])\n",
    "\n",
    "#extract the information from the string in the game column\n",
    "pattern = r'(\\d{4}-\\d{2}-\\d{2}) - ([\\w\\s]+) (\\d+), ([\\w\\s]+) (\\d+)'\n",
    "master_df[['Date', 'AwayTeam', 'AwayScore', 'HomeTeam', 'HomeScore']] = master_df['Game'].str.extract(pattern)\n",
    "master_df['HomeResult'] = 'Draw'\n",
    "master_df.loc[master_df['HomeScore'] > master_df['AwayScore'], 'HomeResult'] = 'Won'\n",
    "master_df.loc[master_df['HomeScore'] < master_df['AwayScore'], 'HomeResult'] = 'Lost'\n",
    "filt_df = master_df.iloc[1::2]\n",
    "filt_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the data from each year into one file for each team to then iterate through to pull the stats for each game\n",
    "year_directories = ['average_data/avg_20_21/', 'average_data/avg_21_22/', 'average_data/avg_22_23/']\n",
    "\n",
    "combined_directory = 'stats'\n",
    "os.makedirs(combined_directory, exist_ok=True)\n",
    "\n",
    "\n",
    "team_dfs = {}\n",
    "\n",
    "for directory in year_directories:\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            team_name = filename.replace('_games.csv', '')\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            df = pd.read_csv(file_path)\n",
    "            cols_to_drop = ['Date','AwayTeam','AwayScore','HomeTeam','HomeScore','HomeResult']\n",
    "            df.drop(columns=cols_to_drop, inplace=True)\n",
    "            if team_name in team_dfs:\n",
    "                team_dfs[team_name] = pd.concat([team_dfs[team_name], df])\n",
    "            else:\n",
    "                team_dfs[team_name] = df\n",
    "\n",
    "for team_name, df in team_dfs.items():\n",
    "    output_path = os.path.join(combined_directory, f'{team_name}')\n",
    "    df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the master dataframe with all of the games and add the stats for the home team, adding a prefix of h to the stat to indicate is is from the home team, creating a new dataframe with all of the home stats\n",
    "games_df = filt_df\n",
    "#create the function to add the hoem team stats\n",
    "def add_home_team_stats(row):\n",
    "    team_name = row['HomeTeam']\n",
    "    file_path = f'stats/{team_name}.csv'\n",
    "    team_stats_df = pd.read_csv(file_path)\n",
    "    game_row = team_stats_df[team_stats_df['Game'] == row['Game']]\n",
    "    if not game_row.empty:\n",
    "        team_stats = game_row.add_prefix('h_').iloc[0]\n",
    "        team_stats.rename({'h_Game': 'Game'}, inplace=True)\n",
    "        for col in team_stats.index:\n",
    "            row[col] = team_stats[col]\n",
    "    return row\n",
    "#initiate the list of updated rows with the stats\n",
    "updated_rows = []\n",
    "#call the function on every row\n",
    "for index, row in games_df.iterrows():\n",
    "    row = add_home_team_stats(row) \n",
    "    updated_rows.append(row)\n",
    "hgames_df = pd.DataFrame(updated_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat the previous step but for away team stats\n",
    "games_df = filt_df\n",
    "\n",
    "def add_away_team_stats(row):\n",
    "    team_name = row['AwayTeam']\n",
    "    file_path = f'stats/{team_name}.csv'\n",
    "    team_stats_df = pd.read_csv(file_path)\n",
    "    game_row = team_stats_df[team_stats_df['Game'] == row['Game']]\n",
    "    if not game_row.empty:\n",
    "        team_stats = game_row.add_prefix('a_').iloc[0]\n",
    "        team_stats.rename({'a_Game': 'Game'}, inplace=True)\n",
    "        for col in team_stats.index:\n",
    "            row[col] = team_stats[col]\n",
    "    return row\n",
    "\n",
    "updated_rows = []\n",
    "for index, row in games_df.iterrows():\n",
    "    row = add_away_team_stats(row) \n",
    "    updated_rows.append(row)\n",
    "agames_df = pd.DataFrame(updated_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luken\\AppData\\Local\\Temp\\ipykernel_6820\\2273431247.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.drop(columns=cols_to_drop, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#merge the two dataframes to create one master dataframe with all the away and home team stats, then save the datraframe to the a csv file\n",
    "import pandas as pd\n",
    "common_columns = ['Game', 'Date', 'AwayTeam', 'AwayScore', 'HomeTeam', 'HomeScore', 'HomeResult']\n",
    "\n",
    "merged_df = pd.merge(agames_df, hgames_df, on=common_columns, how='outer')\n",
    "df2 = merged_df.dropna()\n",
    "cols_to_drop = ['a_Team','h_Team']\n",
    "df2.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "df2.to_csv('training_set.csv', index=False)\n",
    "#the training set is now stored in \"training_set.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
